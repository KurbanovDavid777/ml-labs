{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyNNrDVBxIcg+NQuJlyv81GO"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Данные взяты из ЛР_6 (их подготовка была в 6 лабе)\n","\n","чем вдохновлялся:\n","1) Прикладное машинное обучение с помощью Scikit-Learn и TensorFlow:\n","концепции, инструменты и техники для создания интеллектуальных систем\n","2) https://habr.com/ru/companies/otus/articles/816667/"],"metadata":{"id":"5d3F-OQrNw-H"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"UyI0UljlMZkd","executionInfo":{"status":"ok","timestamp":1763318131474,"user_tz":-180,"elapsed":1065,"user":{"displayName":"Давид Курбанов","userId":"02393001750452980969"}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np"]},{"cell_type":"code","source":["!pip install tensorflow"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jFeWGd63o-Ga","executionInfo":{"status":"ok","timestamp":1763363257167,"user_tz":-180,"elapsed":5144,"user":{"displayName":"Давид Курбанов","userId":"02393001750452980969"}},"outputId":"2193a604-0bc9-4d8a-d339-8ad5b0780a8e"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.9.23)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.6.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.0)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.2.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.1)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.76.0)\n","Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n","Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n","Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.2)\n","Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.15.1)\n","Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.3)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n","Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n","Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n","Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.17.0)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.10.5)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.10)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.3)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"]}]},{"cell_type":"code","source":["X_train=pd.read_csv('/content/X_train.csv')\n","X_test=pd.read_csv('/content/X_test.csv')\n","\n","y_train=pd.read_csv('/content/y_train.csv')\n","y_test=pd.read_csv('/content/y_test.csv')"],"metadata":{"id":"jrIOSZSLOA1H","executionInfo":{"status":"ok","timestamp":1763319832940,"user_tz":-180,"elapsed":44,"user":{"displayName":"Давид Курбанов","userId":"02393001750452980969"}}},"execution_count":51,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf"],"metadata":{"id":"mH-S9-JpCBdX","executionInfo":{"status":"ok","timestamp":1763319487519,"user_tz":-180,"elapsed":12,"user":{"displayName":"Давид Курбанов","userId":"02393001750452980969"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["# X_train_tf = tf.constant(X_train.values, dtype=tf.float32)\n","# X_test_tf  = tf.constant(X_test.values,  dtype=tf.float32)\n","\n","# y_train_tf = tf.constant(y_train.values, dtype=tf.float32)\n","# y_test_tf  = tf.constant(y_test.values,  dtype=tf.float32)"],"metadata":{"id":"sbj6W96tCDo6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X = tf.constant(X_train.values, dtype=tf.float32)\n","\n","y = tf.constant(y_train.values, dtype=tf.float32)"],"metadata":{"id":"_MIg5QfYCF6J","executionInfo":{"status":"ok","timestamp":1763319833867,"user_tz":-180,"elapsed":8,"user":{"displayName":"Давид Курбанов","userId":"02393001750452980969"}}},"execution_count":52,"outputs":[]},{"cell_type":"code","source":["learning_rate = 0.005\n","epochs = 1000"],"metadata":{"id":"F9IZ0-SeCfc7","executionInfo":{"status":"ok","timestamp":1763319834487,"user_tz":-180,"elapsed":20,"user":{"displayName":"Давид Курбанов","userId":"02393001750452980969"}}},"execution_count":53,"outputs":[]},{"cell_type":"code","source":["n_samples = X.shape[0]"],"metadata":{"id":"k1K5nwUfCjS3","executionInfo":{"status":"ok","timestamp":1763319835264,"user_tz":-180,"elapsed":7,"user":{"displayName":"Давид Курбанов","userId":"02393001750452980969"}}},"execution_count":54,"outputs":[]},{"cell_type":"markdown","source":["# Регрессионная модель"],"metadata":{"id":"UjcusxAmPSZ1"}},{"cell_type":"markdown","source":["Функция для создания слоев"],"metadata":{"id":"SgMR33iWQuXc"}},{"cell_type":"code","source":["def neuron_layer(X, n_neurons, name, activation=None):\n","  with tf.name_scope(name):\n","    n_inputs = X.shape[1]\n","    stddev = 2 / np.sqrt(n_inputs + n_neurons)\n","    init = tf.random.truncated_normal((n_inputs, n_neurons), stddev=stddev)\n","    W = tf.Variable(init, name=\"kernel\")\n","    b = tf.Variable(tf.zeros([n_neurons]), name=\"bias\")\n","    Z = tf.matmul(X, W) + b\n","    if activation is not None:\n","      return Z, W, b, activation(Z)\n","    else:\n","      return Z, W, b, Z\n","\n","def relu(Z):\n","    return tf.maximum(0.0, Z)\n","\n","def relu_derivative(Z):\n","    return tf.cast(Z > 0, tf.float32)"],"metadata":{"id":"xSN6vUquQyca","executionInfo":{"status":"ok","timestamp":1763318331406,"user_tz":-180,"elapsed":3,"user":{"displayName":"Давид Курбанов","userId":"02393001750452980969"}}},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":["## Первая модель с 2-мя скрытыми слоями и с функцией активации ReLU"],"metadata":{"id":"r_Xrw-NcCS_i"}},{"cell_type":"code","source":["n_inputs = 10\n","n_hidden_1 = 64\n","n_hidden_2 = 32\n","n_outputs = 1"],"metadata":{"id":"QNbiIOT9CIuj","executionInfo":{"status":"ok","timestamp":1763319594340,"user_tz":-180,"elapsed":45,"user":{"displayName":"Давид Курбанов","userId":"02393001750452980969"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["Z1, W1, b1, A1 = neuron_layer(X, n_hidden_1, \"hidden1\", activation=None)\n","Z2, W2, b2, A2 = neuron_layer(tf.zeros([X.shape[0], n_hidden_1]), n_hidden_2, \"hidden2\", activation=None)\n","Z3, W3, b3, output = neuron_layer(tf.zeros([X.shape[0], n_hidden_2]), n_outputs, \"output\", activation=None)"],"metadata":{"id":"BHzes428UDpU","executionInfo":{"status":"ok","timestamp":1763319596234,"user_tz":-180,"elapsed":42,"user":{"displayName":"Давид Курбанов","userId":"02393001750452980969"}}},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":["Функция потерь MSE"],"metadata":{"id":"BAlCnvLBWYkA"}},{"cell_type":"code","source":["def mse_loss(y_true, y_pred):\n","  return tf.reduce_mean(tf.square(y_true - y_pred))"],"metadata":{"id":"u6AEHGYXWamG","executionInfo":{"status":"ok","timestamp":1763319599605,"user_tz":-180,"elapsed":9,"user":{"displayName":"Давид Курбанов","userId":"02393001750452980969"}}},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":["**Обучение**"],"metadata":{"id":"Yy_KGu6RCmXC"}},{"cell_type":"code","source":["for epoch in range(epochs):\n","  Z1 = tf.matmul(X, W1) + b1\n","  A1 = relu(Z1)\n","\n","  Z2 = tf.matmul(A1, W2) + b2\n","  A2 = relu(Z2)\n","\n","  Z3 = tf.matmul(A2, W3) + b3\n","  output= Z3\n","\n","  loss = mse_loss(y, output)\n","\n","  dLoss_dOutput = 2 * (output - y) / n_samples\n","\n","  dLoss_dW3 = tf.matmul(tf.transpose(A2), dLoss_dOutput)\n","  dLoss_db3 = tf.reduce_sum(dLoss_dOutput, axis=0, keepdims=True)\n","\n","  dLoss_dA2 = tf.matmul(dLoss_dOutput, tf.transpose(W3))\n","  dLoss_dZ2 = dLoss_dA2 * relu_derivative(Z2)\n","  dLoss_dW2 = tf.matmul(tf.transpose(A1), dLoss_dZ2)\n","  dLoss_db2 = tf.reduce_sum(dLoss_dZ2, axis=0, keepdims=True)\n","\n","  dLoss_dA1 = tf.matmul(dLoss_dZ2, tf.transpose(W2))\n","  dLoss_dZ1 = dLoss_dA1 * relu_derivative(Z1)\n","  dLoss_dW1 = tf.matmul(tf.transpose(X), dLoss_dZ1)\n","  dLoss_db1 = tf.reduce_sum(dLoss_dZ1, axis=0, keepdims=True)\n","\n","  W3.assign_sub(learning_rate * dLoss_dW3)\n","  b3.assign_sub(learning_rate * tf.squeeze(dLoss_db3, axis=0))\n","  W2.assign_sub(learning_rate * dLoss_dW2)\n","  b2.assign_sub(learning_rate * tf.squeeze(dLoss_db2, axis=0))\n","  W1.assign_sub(learning_rate * dLoss_dW1)\n","  b1.assign_sub(learning_rate * tf.squeeze(dLoss_db1, axis=0))\n","\n","  if epoch % 50 == 0:\n","    print(f\"Epoch {epoch}, Loss: {loss.numpy()}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_w6XhK9wdIXL","executionInfo":{"status":"ok","timestamp":1763319666919,"user_tz":-180,"elapsed":17369,"user":{"displayName":"Давид Курбанов","userId":"02393001750452980969"}},"outputId":"7be4c119-b441-4261-b915-c6b390bc2577"},"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 0, Loss: 3773.47802734375\n","Epoch 50, Loss: 198.64723205566406\n","Epoch 100, Loss: 184.4783172607422\n","Epoch 150, Loss: 179.2926788330078\n","Epoch 200, Loss: 173.9338836669922\n","Epoch 250, Loss: 168.58375549316406\n","Epoch 300, Loss: 164.48976135253906\n","Epoch 350, Loss: 161.01673889160156\n","Epoch 400, Loss: 157.88558959960938\n","Epoch 450, Loss: 155.43576049804688\n","Epoch 500, Loss: 153.1112060546875\n","Epoch 550, Loss: 151.34063720703125\n","Epoch 600, Loss: 149.54693603515625\n","Epoch 650, Loss: 148.1747589111328\n","Epoch 700, Loss: 146.6547393798828\n","Epoch 750, Loss: 145.54074096679688\n","Epoch 800, Loss: 144.27525329589844\n","Epoch 850, Loss: 143.2101287841797\n","Epoch 900, Loss: 142.04637145996094\n","Epoch 950, Loss: 140.65518188476562\n"]}]},{"cell_type":"markdown","source":["## Вторая модель с 3-мя скрытыми слоями, а также с тангенсиальной функцией активации"],"metadata":{"id":"ExQmTMS8kAMl"}},{"cell_type":"code","source":["n_hidden_1 = 256\n","n_hidden_2 = 64\n","n_hidden_3 = 32\n","n_outputs = 1"],"metadata":{"id":"GSYWZ3IKkLPy","executionInfo":{"status":"ok","timestamp":1763319734440,"user_tz":-180,"elapsed":11,"user":{"displayName":"Давид Курбанов","userId":"02393001750452980969"}}},"execution_count":46,"outputs":[]},{"cell_type":"code","source":["def tanh(Z):\n","    return tf.math.tanh(Z)\n","\n","def tanh_derivative(Z):\n","    return 1 - tf.math.tanh(Z)**2"],"metadata":{"id":"sGMFVxevkQ3Q","executionInfo":{"status":"ok","timestamp":1763319735068,"user_tz":-180,"elapsed":10,"user":{"displayName":"Давид Курбанов","userId":"02393001750452980969"}}},"execution_count":47,"outputs":[]},{"cell_type":"code","source":["Z1, W1, b1, A1 = neuron_layer(X, n_hidden_1, \"hidden1\", activation=relu)\n","Z2, W2, b2, A2 = neuron_layer(tf.zeros([X.shape[0], n_hidden_1]), n_hidden_2, \"hidden2\", activation=tanh)\n","Z3, W3, b3, A3 = neuron_layer(tf.zeros([X.shape[0], n_hidden_2]), n_hidden_3, \"hidden3\", activation=tanh)\n","Z4, W4, b4, output = neuron_layer(tf.zeros([X.shape[0], n_hidden_3]), n_outputs, \"output\", activation=None)\n"],"metadata":{"id":"bm9jsP2gkQTc","executionInfo":{"status":"ok","timestamp":1763319735979,"user_tz":-180,"elapsed":33,"user":{"displayName":"Давид Курбанов","userId":"02393001750452980969"}}},"execution_count":48,"outputs":[]},{"cell_type":"markdown","source":["**Обучение**"],"metadata":{"id":"geiLwMkJlOKY"}},{"cell_type":"code","source":["for epoch in range(epochs):\n","\n","    Z1 = tf.matmul(X, W1) + b1\n","    A1 = relu(Z1)\n","\n","    Z2 = tf.matmul(A1, W2) + b2\n","    A2 = tanh(Z2)\n","\n","    Z3 = tf.matmul(A2, W3) + b3\n","    A3 = tanh(Z3)\n","\n","    Z4 = tf.matmul(A3, W4) + b4\n","    output = Z4\n","\n","    loss = mse_loss(y, output)\n","\n","    dLoss_dOutput = 2 * (output - y) / n_samples\n","\n","    dLoss_dW4 = tf.matmul(tf.transpose(A3), dLoss_dOutput)\n","    dLoss_db4 = tf.reduce_sum(dLoss_dOutput, axis=0, keepdims=True)\n","\n","    dLoss_dA3 = tf.matmul(dLoss_dOutput, tf.transpose(W4))\n","    dLoss_dZ3 = dLoss_dA3 * tanh_derivative(Z3)\n","    dLoss_dW3 = tf.matmul(tf.transpose(A2), dLoss_dZ3)\n","    dLoss_db3 = tf.reduce_sum(dLoss_dZ3, axis=0, keepdims=True)\n","\n","    dLoss_dA2 = tf.matmul(dLoss_dZ3, tf.transpose(W3))\n","    dLoss_dZ2 = dLoss_dA2 * tanh_derivative(Z2)\n","    dLoss_dW2 = tf.matmul(tf.transpose(A1), dLoss_dZ2)\n","    dLoss_db2 = tf.reduce_sum(dLoss_dZ2, axis=0, keepdims=True)\n","\n","    dLoss_dA1 = tf.matmul(dLoss_dZ2, tf.transpose(W2))\n","    dLoss_dZ1 = dLoss_dA1 * relu_derivative(Z1)\n","    dLoss_dW1 = tf.matmul(tf.transpose(X), dLoss_dZ1)\n","    dLoss_db1 = tf.reduce_sum(dLoss_dZ1, axis=0, keepdims=True)\n","\n","    W4.assign_sub(learning_rate * dLoss_dW4)\n","    b4.assign_sub(learning_rate * tf.squeeze(dLoss_db4, axis=0))\n","    W3.assign_sub(learning_rate * dLoss_dW3)\n","    b3.assign_sub(learning_rate * tf.squeeze(dLoss_db3, axis=0))\n","    W2.assign_sub(learning_rate * dLoss_dW2)\n","    b2.assign_sub(learning_rate * tf.squeeze(dLoss_db2, axis=0))\n","    W1.assign_sub(learning_rate * dLoss_dW1)\n","    b1.assign_sub(learning_rate * tf.squeeze(dLoss_db1, axis=0))\n","\n","    if epoch % 50 == 0:\n","        print(f\"Epoch {epoch}, Loss: {loss.numpy()}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fUzw-6qhlN5z","executionInfo":{"status":"ok","timestamp":1763319820471,"user_tz":-180,"elapsed":74875,"user":{"displayName":"Давид Курбанов","userId":"02393001750452980969"}},"outputId":"68647f5c-4577-40c6-bb0b-16c5960244f0"},"execution_count":49,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 0, Loss: 3876.35498046875\n","Epoch 50, Loss: 227.5876922607422\n","Epoch 100, Loss: 169.0169677734375\n","Epoch 150, Loss: 145.1420440673828\n","Epoch 200, Loss: 133.78860473632812\n","Epoch 250, Loss: 124.91207885742188\n","Epoch 300, Loss: 122.67548370361328\n","Epoch 350, Loss: 121.70854949951172\n","Epoch 400, Loss: 116.48747253417969\n","Epoch 450, Loss: 114.13533782958984\n","Epoch 500, Loss: 112.1841049194336\n","Epoch 550, Loss: 110.55619812011719\n","Epoch 600, Loss: 109.0429458618164\n","Epoch 650, Loss: 108.16889953613281\n","Epoch 700, Loss: 106.541748046875\n","Epoch 750, Loss: 105.1368637084961\n","Epoch 800, Loss: 103.68286895751953\n","Epoch 850, Loss: 102.15996551513672\n","Epoch 900, Loss: 100.84544372558594\n","Epoch 950, Loss: 101.54236602783203\n"]}]},{"cell_type":"markdown","source":["## Третья модель с 4-мя скрытыми слоями, а также с тангенсиальной функцией активации"],"metadata":{"id":"pPI1TsB76Haj"}},{"cell_type":"code","source":["n_hidden_1 = 256\n","n_hidden_2 = 64\n","n_hidden_3 = 32\n","n_hidden_4 = 16\n","n_outputs = 1"],"metadata":{"id":"rJdvNwNP7zH3","executionInfo":{"status":"ok","timestamp":1763319840880,"user_tz":-180,"elapsed":8,"user":{"displayName":"Давид Курбанов","userId":"02393001750452980969"}}},"execution_count":55,"outputs":[]},{"cell_type":"code","source":["Z1, W1, b1, A1 = neuron_layer(X, n_hidden_1, \"hidden1\", activation=relu)\n","Z2, W2, b2, A2 = neuron_layer(tf.zeros([X.shape[0], n_hidden_1]), n_hidden_2, \"hidden2\", activation=tanh)\n","Z3, W3, b3, A3 = neuron_layer(tf.zeros([X.shape[0], n_hidden_2]), n_hidden_3, \"hidden3\", activation=relu)\n","Z4, W4, b4, A4 = neuron_layer(tf.zeros([X.shape[0], n_hidden_3]), n_hidden_4, \"hidden4\", activation=tanh)\n","Z5, W5, b5, output = neuron_layer(tf.zeros([X.shape[0], n_hidden_4]), n_outputs, \"output\", activation=None)"],"metadata":{"id":"Y-Lr7J_18EmH","executionInfo":{"status":"ok","timestamp":1763319842334,"user_tz":-180,"elapsed":43,"user":{"displayName":"Давид Курбанов","userId":"02393001750452980969"}}},"execution_count":56,"outputs":[]},{"cell_type":"code","source":["for epoch in range(epochs):\n","\n","    Z1 = tf.matmul(X, W1) + b1\n","    A1 = relu(Z1)\n","\n","    Z2 = tf.matmul(A1, W2) + b2\n","    A2 = tanh(Z2)\n","\n","    Z3 = tf.matmul(A2, W3) + b3\n","    A3 = relu(Z3)\n","\n","    Z4 = tf.matmul(A3, W4) + b4\n","    A4 = tanh(Z4)\n","\n","    Z5 = tf.matmul(A4, W5) + b5\n","    output = Z5\n","\n","    loss = mse_loss(y, output)\n","\n","    dLoss_dOutput = 2 * (output - y) / n_samples\n","\n","    dLoss_dW5 = tf.matmul(tf.transpose(A4), dLoss_dOutput)\n","    dLoss_db5 = tf.reduce_sum(dLoss_dOutput, axis=0, keepdims=True)\n","\n","    dLoss_dA4 = tf.matmul(dLoss_dOutput, tf.transpose(W5))\n","    dLoss_dZ4 = dLoss_dA4 * tanh_derivative(Z4)\n","    dLoss_dW4 = tf.matmul(tf.transpose(A3), dLoss_dZ4)\n","    dLoss_db4 = tf.reduce_sum(dLoss_dZ4, axis=0, keepdims=True)\n","\n","    dLoss_dA3 = tf.matmul(dLoss_dZ4, tf.transpose(W4))\n","    dLoss_dZ3 = dLoss_dA3 * relu_derivative(Z3)\n","    dLoss_dW3 = tf.matmul(tf.transpose(A2), dLoss_dZ3)\n","    dLoss_db3 = tf.reduce_sum(dLoss_dZ3, axis=0, keepdims=True)\n","\n","    dLoss_dA2 = tf.matmul(dLoss_dZ3, tf.transpose(W3))\n","    dLoss_dZ2 = dLoss_dA2 * tanh_derivative(Z2)\n","    dLoss_dW2 = tf.matmul(tf.transpose(A1), dLoss_dZ2)\n","    dLoss_db2 = tf.reduce_sum(dLoss_dZ2, axis=0, keepdims=True)\n","\n","    dLoss_dA1 = tf.matmul(dLoss_dZ2, tf.transpose(W2))\n","    dLoss_dZ1 = dLoss_dA1 * relu_derivative(Z1)\n","    dLoss_dW1 = tf.matmul(tf.transpose(X), dLoss_dZ1)\n","    dLoss_db1 = tf.reduce_sum(dLoss_dZ1, axis=0, keepdims=True)\n","\n","    W5.assign_sub(learning_rate * dLoss_dW5)\n","    b5.assign_sub(learning_rate * tf.squeeze(dLoss_db5, axis=0))\n","    W4.assign_sub(learning_rate * dLoss_dW4)\n","    b4.assign_sub(learning_rate * tf.squeeze(dLoss_db4, axis=0))\n","    W3.assign_sub(learning_rate * dLoss_dW3)\n","    b3.assign_sub(learning_rate * tf.squeeze(dLoss_db3, axis=0))\n","    W2.assign_sub(learning_rate * dLoss_dW2)\n","    b2.assign_sub(learning_rate * tf.squeeze(dLoss_db2, axis=0))\n","    W1.assign_sub(learning_rate * dLoss_dW1)\n","    b1.assign_sub(learning_rate * tf.squeeze(dLoss_db1, axis=0))\n","\n","    if epoch % 50 == 0:\n","        print(f\"Epoch {epoch}, Loss: {loss.numpy()}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C13bqCEP8V7u","executionInfo":{"status":"ok","timestamp":1763319920822,"user_tz":-180,"elapsed":77027,"user":{"displayName":"Давид Курбанов","userId":"02393001750452980969"}},"outputId":"7019dafb-d56a-4d18-b411-c69da650c2fe"},"execution_count":57,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 0, Loss: 3887.554443359375\n","Epoch 50, Loss: 298.17840576171875\n","Epoch 100, Loss: 248.35147094726562\n","Epoch 150, Loss: 183.6991424560547\n","Epoch 200, Loss: 163.6563262939453\n","Epoch 250, Loss: 255.3255615234375\n","Epoch 300, Loss: 151.0913848876953\n","Epoch 350, Loss: 134.2249755859375\n","Epoch 400, Loss: 130.45274353027344\n","Epoch 450, Loss: 135.17880249023438\n","Epoch 500, Loss: 117.2361831665039\n","Epoch 550, Loss: 121.71372985839844\n","Epoch 600, Loss: 110.02201843261719\n","Epoch 650, Loss: 118.68744659423828\n","Epoch 700, Loss: 102.10443115234375\n","Epoch 750, Loss: 109.78971099853516\n","Epoch 800, Loss: 122.42039489746094\n","Epoch 850, Loss: 102.56536865234375\n","Epoch 900, Loss: 101.29076385498047\n","Epoch 950, Loss: 94.26465606689453\n"]}]},{"cell_type":"markdown","source":["# Вывод"],"metadata":{"id":"spvuyP9yEeL2"}},{"cell_type":"markdown","source":["\n","В работе была реализована простая полносвязная нейронная сеть для задачи регрессии полностью с нуля, без использования готовых слоёв, функций потерь и оптимизаторов. Все вычисления выполнены только через базовые операции TensorFlow.\n","\n","**1. Экспериментальные архитектуры**\n","\n","*Модель 1* — 2 скрытых слоя (64 → 32), ReLU–ReLU\n","Финальная ошибка: ~140.6\n","\n","*Модель 2* — 3 скрытых слоя (256 → 64 → 32), ReLU–tanh–tanh\n","Финальная ошибка: ~101.5\n","\n","*Модель 3* — 4 скрытых слоя (256 → 64 → 32 → 16), ReLU–tanh–ReLU–tanh\n","Финальная ошибка: ~94.2  \n","Это лучшая модель.\n","\n","**2. Выбор функций активации**\n","\n","- В начальных слоях использовалась ReLU, так как она устойчива к затуханию градиента и позволяет эффективно извлекать признаки.\n","- В более глубоких слоях использовалась tanh для стабилизации значений и повышения нелинейности.\n","- В выходном слое активация не использовалась, что правильно для регрессии.\n","\n","**3. Выбор функции потерь**\n","\n","В качестве функции потерь применена Mean Squared Error (MSE), так как задача является регрессией. MSE проста для ручной реализации градиента и чувствительна к большим ошибкам.\n","\n","**4. Динамика обучения**\n","\n","- Во всех моделях ошибка быстро снижалась в начале обучения.\n","- У более глубоких моделей наблюдались небольшие скачки ошибки, что связано скорее всего с использованием простого SGD.\n","- Самая глубокая модель показала наилучшую сходимость и минимальную ошибку.\n","\n","**Итог**\n","\n","Более глубокие архитектуры и комбинации ReLU и tanh улучшают качество модели. Лучшая сеть достигла ошибки около 94. Это хороший результат для модели, обученной полностью вручную. Выполнена реализация полного цикла обучения: прямой проход, обратное распространение ошибки, вычисление градиентов и обновление параметров.\n"],"metadata":{"id":"x30AyViMoKIY"}},{"cell_type":"code","source":[],"metadata":{"id":"UubzdSKyEdlp"},"execution_count":null,"outputs":[]}]}